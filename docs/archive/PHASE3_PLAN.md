# Phase 3 Implementation Plan

**Objective**: Implement Edge Runtime with file system-based dataset management

**Status**: Planning
**Start Date**: 2025-10-26
**Target Completion**: 2-3 weeks

---

## ğŸ¯ Phase 3 Scope

### Core Deliverables

1. **Dataset Manager** (File System Storage)
   - JSONL-based execution logging
   - Daily log rotation
   - Local analytics generation
   - Retention policy enforcement

2. **Configuration Manager**
   - YAML-based configuration
   - Environment variable support
   - Runtime configuration validation

3. **Artifact Cache**
   - Local artifact storage
   - Version management with symlinks
   - Artifact download (stub for v0.1)

4. **Edge Runtime API**
   - Simple REST API for execution
   - Execute endpoint with logging
   - Health check endpoint

5. **Docker Deployment**
   - Dockerfile for edge runtime
   - Volume mounting for /loopai-data
   - Environment configuration

### Out of Scope (for Phase 4)

- SignalR real-time communication
- Cloud telemetry upload
- A/B testing framework
- Privacy filters (PII detection)
- Multi-language support

---

## ğŸ“‹ Implementation Phases

### Phase 3.1: Dataset Manager (Week 1)

**TDD Approach**:
1. Create `tests/test_phase3_dataset_manager.py`
2. Test file system structure creation
3. Test JSONL execution logging
4. Test daily log rotation
5. Test retention policy
6. Implement Dataset Manager

**Components**:
```python
src/loopai/runtime/
â”œâ”€â”€ __init__.py
â””â”€â”€ dataset_manager.py
    â”œâ”€â”€ DatasetManager
    â”œâ”€â”€ ExecutionLogger
    â”œâ”€â”€ ValidationLogger
    â””â”€â”€ AnalyticsGenerator
```

**File System Structure**:
```
/loopai-data/
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ {task_id}/
â”‚       â”œâ”€â”€ executions/
â”‚       â”‚   â””â”€â”€ YYYY-MM-DD.jsonl  (append-only)
â”‚       â”œâ”€â”€ validations/
â”‚       â”‚   â””â”€â”€ sampled-YYYY-MM-DD.jsonl
â”‚       â””â”€â”€ analytics/
â”‚           â””â”€â”€ daily-stats-YYYY-MM-DD.json
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ {task_id}/
â”‚       â”œâ”€â”€ v1/
â”‚       â”‚   â”œâ”€â”€ program.py
â”‚       â”‚   â””â”€â”€ metadata.json
â”‚       â”œâ”€â”€ v2/
â”‚       â””â”€â”€ active -> v2/  (symlink)
â””â”€â”€ config/
    â””â”€â”€ deployment.yaml
```

**Tests**:
- âœ… Create directory structure
- âœ… Write execution record to JSONL
- âœ… Append multiple records
- âœ… Read execution logs
- âœ… Generate daily analytics
- âœ… Enforce retention policy (delete old logs)

### Phase 3.2: Configuration Manager (Week 1)

**TDD Approach**:
1. Create configuration tests
2. Test YAML loading
3. Test environment variable substitution
4. Test validation
5. Implement Configuration Manager

**Components**:
```python
src/loopai/runtime/
â””â”€â”€ config_manager.py
    â”œâ”€â”€ ConfigurationManager
    â”œâ”€â”€ DeploymentConfig (Pydantic model)
    â””â”€â”€ validate_config()
```

**Configuration Schema**:
```yaml
runtime:
  mode: edge  # edge, central, hybrid
  data_dir: /loopai-data

execution:
  worker_count: 4
  timeout_ms: 1000

sampling:
  strategy: random
  rate: 0.05

storage:
  retention_days: 7
  max_size_gb: 100
```

**Tests**:
- âœ… Load configuration from YAML
- âœ… Environment variable substitution
- âœ… Validation (required fields, types)
- âœ… Default values
- âœ… Invalid configuration errors

### Phase 3.3: Artifact Cache (Week 1-2)

**TDD Approach**:
1. Create artifact cache tests
2. Test artifact storage
3. Test version management
4. Test symlink to active version
5. Implement Artifact Cache

**Components**:
```python
src/loopai/runtime/
â””â”€â”€ artifact_cache.py
    â”œâ”€â”€ ArtifactCache
    â”œâ”€â”€ store_artifact()
    â”œâ”€â”€ get_active_artifact()
    â””â”€â”€ set_active_version()
```

**Tests**:
- âœ… Store artifact with version
- âœ… List artifact versions
- âœ… Get active artifact via symlink
- âœ… Update active version (change symlink)
- âœ… Load artifact metadata

### Phase 3.4: Edge Runtime API (Week 2)

**TDD Approach**:
1. Create API tests
2. Test /execute endpoint
3. Test /health endpoint
4. Test integration with dataset manager
5. Implement FastAPI runtime

**Components**:
```python
src/loopai/runtime/
â”œâ”€â”€ api.py  (FastAPI app)
â””â”€â”€ edge_runtime.py
    â””â”€â”€ EdgeRuntime (orchestrator)
```

**Endpoints**:
```
POST /execute
  Body: {"input": {"text": "..."}}
  Response: {"output": "...", "latency_ms": 5.2}

GET /health
  Response: {"status": "healthy", "version": "0.1.0"}

GET /metrics
  Response: {"executions_today": 1000, "avg_latency_ms": 4.5}
```

**Tests**:
- âœ… Execute endpoint returns result
- âœ… Execution logged to JSONL
- âœ… Latency measured
- âœ… Health endpoint responds
- âœ… Metrics endpoint shows stats

### Phase 3.5: Docker Deployment (Week 2)

**Components**:
- `Dockerfile` (edge runtime image)
- `docker-compose.yml` (local testing)
- `.dockerignore`

**Dockerfile**:
```dockerfile
FROM python:3.9-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY src/ ./src/

VOLUME /loopai-data

EXPOSE 8080

CMD ["uvicorn", "loopai.runtime.api:app", "--host", "0.0.0.0", "--port", "8080"]
```

**Tests**:
- âœ… Docker build succeeds
- âœ… Container starts
- âœ… API accessible on port 8080
- âœ… Volume mounted correctly
- âœ… Logs written to volume

### Phase 3.6: Integration Testing (Week 3)

**End-to-End Tests**:
```python
tests/test_phase3_integration.py
```

**Scenarios**:
1. âœ… Generate program â†’ Store artifact â†’ Execute via API â†’ Verify JSONL log
2. âœ… Multiple executions â†’ Daily analytics generated
3. âœ… Retention policy â†’ Old logs deleted
4. âœ… Docker deployment â†’ Full workflow

---

## ğŸ§ª TDD Test Structure

```
tests/
â”œâ”€â”€ test_phase3_dataset_manager.py     (Week 1)
â”‚   â”œâ”€â”€ test_create_directory_structure
â”‚   â”œâ”€â”€ test_log_execution
â”‚   â”œâ”€â”€ test_append_executions
â”‚   â”œâ”€â”€ test_read_logs
â”‚   â”œâ”€â”€ test_generate_analytics
â”‚   â””â”€â”€ test_retention_policy
â”‚
â”œâ”€â”€ test_phase3_config_manager.py      (Week 1)
â”‚   â”œâ”€â”€ test_load_yaml_config
â”‚   â”œâ”€â”€ test_env_var_substitution
â”‚   â”œâ”€â”€ test_config_validation
â”‚   â”œâ”€â”€ test_default_values
â”‚   â””â”€â”€ test_invalid_config_error
â”‚
â”œâ”€â”€ test_phase3_artifact_cache.py      (Week 1-2)
â”‚   â”œâ”€â”€ test_store_artifact
â”‚   â”œâ”€â”€ test_list_versions
â”‚   â”œâ”€â”€ test_get_active_artifact
â”‚   â”œâ”€â”€ test_update_active_version
â”‚   â””â”€â”€ test_load_metadata
â”‚
â”œâ”€â”€ test_phase3_edge_api.py            (Week 2)
â”‚   â”œâ”€â”€ test_execute_endpoint
â”‚   â”œâ”€â”€ test_execution_logged
â”‚   â”œâ”€â”€ test_latency_measured
â”‚   â”œâ”€â”€ test_health_endpoint
â”‚   â””â”€â”€ test_metrics_endpoint
â”‚
â””â”€â”€ test_phase3_integration.py         (Week 3)
    â”œâ”€â”€ test_full_workflow
    â”œâ”€â”€ test_daily_analytics
    â”œâ”€â”€ test_retention_enforcement
    â””â”€â”€ test_docker_deployment
```

**Total**: ~25 tests (TDD approach)

---

## ğŸ“Š Success Criteria

### Functional Requirements

- [x] TDD approach (tests written first)
- [ ] Dataset Manager stores executions in JSONL
- [ ] Daily log rotation works
- [ ] Analytics generated daily
- [ ] Retention policy enforced
- [ ] Configuration loaded from YAML
- [ ] Artifact cache manages versions
- [ ] Active version symlink works
- [ ] REST API executes programs
- [ ] Executions logged automatically
- [ ] Docker deployment works
- [ ] Zero technical debt (no TODOs, proper docs, type hints)

### Performance Requirements

- [ ] Execution latency: <10ms p99 (same as Phase 2)
- [ ] JSONL append: <1ms
- [ ] Analytics generation: <100ms
- [ ] API response: <20ms p99

### Quality Requirements

- [ ] All tests pass
- [ ] Test coverage >80%
- [ ] No TODOs in code
- [ ] All functions have docstrings
- [ ] All functions have type hints
- [ ] Pydantic models for all data

---

## ğŸ”§ Dependencies

**New Dependencies**:
```txt
# Runtime
fastapi==0.104.1
uvicorn==0.24.0
pyyaml==6.0.1

# Testing
httpx==0.25.0  # for FastAPI testing
pytest-asyncio==0.21.1
```

**Existing** (from Phase 0-2):
- pydantic
- pytest
- python-dotenv
- openai

---

## ğŸ“ Project Structure After Phase 3

```
Loopai/
â”œâ”€â”€ src/loopai/
â”‚   â”œâ”€â”€ generator/          âœ… (Phase 0-1)
â”‚   â”œâ”€â”€ executor/           âœ… (Phase 0)
â”‚   â”œâ”€â”€ validator/          âœ… (Phase 1)
â”‚   â”œâ”€â”€ sampler/            âœ… (Phase 1)
â”‚   â”œâ”€â”€ runtime/            ğŸ†• NEW (Phase 3)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ dataset_manager.py
â”‚   â”‚   â”œâ”€â”€ config_manager.py
â”‚   â”‚   â”œâ”€â”€ artifact_cache.py
â”‚   â”‚   â”œâ”€â”€ edge_runtime.py
â”‚   â”‚   â””â”€â”€ api.py
â”‚   â””â”€â”€ models.py           âœ… (extended)
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_phase0.py      âœ…
â”‚   â”œâ”€â”€ test_phase1.py      âœ…
â”‚   â”œâ”€â”€ test_phase2.py      âœ…
â”‚   â”œâ”€â”€ test_phase3_dataset_manager.py   ğŸ†•
â”‚   â”œâ”€â”€ test_phase3_config_manager.py    ğŸ†•
â”‚   â”œâ”€â”€ test_phase3_artifact_cache.py    ğŸ†•
â”‚   â”œâ”€â”€ test_phase3_edge_api.py          ğŸ†•
â”‚   â””â”€â”€ test_phase3_integration.py       ğŸ†•
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_phase2_benchmark.py   âœ…
â”‚   â””â”€â”€ run_edge_runtime.py       ğŸ†• NEW
â”‚
â”œâ”€â”€ Dockerfile                    ğŸ†• NEW
â”œâ”€â”€ docker-compose.yml            ğŸ†• NEW
â”œâ”€â”€ requirements.txt              ğŸ“ Updated
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ PHASE3_PLAN.md            ğŸ†• This document
    â””â”€â”€ PHASE3_STATUS.md          ğŸ†• (created at end)
```

---

## ğŸš€ Getting Started

### Week 1: Dataset & Config Management

**Day 1-2**: Dataset Manager TDD
- Write all dataset manager tests
- Implement Dataset Manager
- Verify all tests pass

**Day 3-4**: Configuration Manager TDD
- Write all config manager tests
- Implement Configuration Manager
- Integration with Dataset Manager

**Day 5**: Artifact Cache TDD (start)
- Write artifact cache tests
- Begin implementation

### Week 2: Runtime & API

**Day 1-2**: Artifact Cache (complete)
- Complete implementation
- All tests passing

**Day 3-4**: Edge Runtime API
- Write API tests
- Implement FastAPI endpoints
- Integration testing

**Day 5**: Docker Deployment
- Create Dockerfile
- Test Docker build
- Verify volume mounting

### Week 3: Integration & Documentation

**Day 1-3**: End-to-End Testing
- Full workflow tests
- Performance validation
- Bug fixes

**Day 4-5**: Documentation
- Create PHASE3_STATUS.md
- Update README.md
- Update ARCHITECTURE.md if needed

---

## ğŸ¯ Milestone Checkpoints

### Checkpoint 1 (End of Week 1)
- âœ… Dataset Manager complete with tests
- âœ… Configuration Manager complete with tests
- âœ… Artifact Cache ~50% complete

### Checkpoint 2 (End of Week 2)
- âœ… Artifact Cache complete
- âœ… Edge Runtime API complete
- âœ… Docker deployment working

### Checkpoint 3 (End of Week 3)
- âœ… All integration tests passing
- âœ… Performance targets met
- âœ… Documentation complete
- âœ… Phase 3 ready for review

---

## âš ï¸ Known Challenges

1. **File System Performance**:
   - JSONL append performance with high throughput
   - Mitigation: Buffer writes, async I/O

2. **Symlink Support**:
   - Windows symlink permissions
   - Mitigation: Check OS, fallback to copy

3. **Docker Volumes**:
   - Permission issues with mounted volumes
   - Mitigation: Proper user/group configuration

4. **Retention Policy**:
   - Disk space management
   - Mitigation: Monitoring, alerts

---

## ğŸ“š References

- **ARCHITECTURE.md**: Full architecture specification
- **Phase 2 Learnings**: TDD approach, zero technical debt
- **FastAPI Documentation**: https://fastapi.tiangolo.com/
- **Docker Best Practices**: https://docs.docker.com/develop/dev-best-practices/

---

**Next Step**: Create Phase 3 Dataset Manager tests and begin TDD implementation.
